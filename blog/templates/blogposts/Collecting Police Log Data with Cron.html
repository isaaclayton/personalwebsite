<div class='text'>

    <p>A few months ago, I wanted to know why a swarm of police cars were rushing down the street I was driving on. While I was searching for the reason, I discovered that my local police department puts up a new police report log on their website every Monday through Friday. The previous log is taken down when the current log is put up, so I've been meaning to figure out how to download the log into a folder, with the intent of eventually analyzing the data.</p>

    <p>I learned how to do this a week ago, so I'll let you in on the secret! The process I'm using is to extract police log data, but you could use it to extract any kind of file that is put up daily. </p>

    <h2>Step 1: Find a server</h2>

    <p>While you could end up using your computer to automate the process, you'd be more prone to problems. Your computer would have to be awake at the same time every day for the processes to run. If you have to wake your computer up at the same time every day, it kind of takes away the beauty of automation. You can keep a server running 24/7 if needed.</p>

    <p>This step could have it's own article dedicated to it. There are a lot of different options, such as DigitalOcean droplets and Windows Azure virtual machines. In this article, I'll be using one of Amazon Web Services' EC2 instances. They're what I'm most familiar with and are pretty easy to set up. Plus, if you've never used Amazon Web Services (AWS) before, you get a <a href="https://aws.amazon.com/free/">year of their free tier</a>). To learn how to set up an EC2 instance, you can read AWS' <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EC2_GetStarted.html">EC2 User Guide</a>.</p>

    <p>The Amazon Machine Image I chose was the "Ubuntu Server 16.04 LTS (HVM), SSD Volume Type". I then chose to make it a t2.nano instance type because downloading a single file every day isn't very intensive, and the t2.nano is the smallest instance that Amazon offers in terms of memory and processing power. As part of the free tier though, you get 750 hours/month free of t2.micro instances. That's 31.25 days, meaning you don't ever have to stop it. Choosing this type might make more sense if this is your only EC2 instance.  Once you have your server activated, you can log into it by following steps 2-4 of <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AccessingInstancesLinux.html">these instructions</a>. </p>

    <h2>Step 2: Wget the wdata <sup><a href='#fn1' id='ref1'>1</a></sup></h2>

    <p>Now that the server is up and running, you need to be able to get the desired file from its website to your server from the command line. The command needed for this is "wget". Wget ("web get") is a Linux/Unix command that downloads a file from a given source. The syntax for this is: </p>

    <div class="codebox">
        <code>
            user@server:/$ wget www.website.com/file.txt -O log.txt</code>
    </div>

    <p>The -O is the letter O not the number 0. The reason it's there is so that we can rename the file to what we want to call it (in this example, as <code>log.txt</code>). The filename doesn't have to change, but it'll be helpful for when we want the filename to reflect a different day or revision. If the website putting up the file already specifies a date/revision when putting it up, you could skip this step, although it would be safe to also version it yourself.</p>

     <p>The way that we're going to version it is as follows:</p>

    <div class="codebox">
        <code>
            user@server:/$ wget www.website.com/file.txt -O log_$(date +%Y%m%d).txt</code>
    </div>

    <p><code>$(date +%Y%m%d)</code> is a <a href="http://www.compciv.org/topics/bash/variables-and-substitution/">command substitution</a>, which means that it'll run the <code>date</code> command in the format YYYYMMDD (e.g. 20181231) and append it to the end of our filename.

    <p>We now have a way of getting the data from the website directly into our server. The next step is deciding where to store it. </p>

    <h2>Step 3: Storing the Data</h2>

    <p>If your server has a lot of storage and the files you're collecting are small, you could just keep the files on your server. If you choose to do this and use the server for other purposes, you should store them in a folder with an appropriate name. The command <code>mkdir foldername</code> will create the folder. Instead of using <code>wget</code> to put the file at <code>filename.txt</code>, put it at <code>foldername/filename.txt</code>.</p>

    <p>The EC2 server I was using didn't have a lot of storage, so I needed to find a different solution. I decided to transfer the files using an S3 bucket. S3 is another service that AWS offers specifically for storage purposes. You can read about setting an S3 bucket up using <a href="https://docs.aws.amazon.com/AmazonS3/latest/gsg/CreatingABucket.html">these instructions</a>. There are a lot of different customizations for S3 buckets, but the default settings will be fine.</p>

    <p>Once your S3 bucket is set up, you'll need to download the <a href='https://aws.amazon.com/cli/'>AWS Command Line Interface (CLI)</a>. This will allow you to access your S3 bucket from the command line. To download the AWS CLI, execute the following commands:</p>

    <div class="codebox">
        <code><pre>
        user@server:/$ sudo apt-get update && sudo apt-get -y upgrade
        user@server:/$ sudo apt-get install python-pip
        user@server:/$ pip install awscli --upgrade --user</pre></code>
    </div>
    
    <p>We're going to need to configure it so that it knows to use our AWS account. </p>


    Duis pretium nulla non tempus convallis. In posuere tempus ex eget malesuada. Curabitur imperdiet purus metus, in consectetur neque consequat sed. Nam tortor risus, laoreet ut nisi quis, consectetur interdum neque. Nulla fermentum suscipit tempus. Suspendisse ultrices tellus quis fermentum dignissim. Aenean augue erat, vestibulum sed sollicitudin ut, vestibulum ac nunc. Pellentesque pellentesque lorem sit amet sollicitudin porttitor. Nulla facilisi. Etiam eget felis elit. Aenean sed ipsum nibh. Sed risus ante, maximus ut mattis et, malesuada ut lorem. Aenean quis velit vel nunc consequat dictum.

    In facilisis orci massa, mattis consequat nunc luctus in. Etiam feugiat, arcu quis porta rhoncus, velit tortor elementum libero, ut tristique quam neque ac augue. Vivamus ut gravida sem. Suspendisse in massa tincidunt, egestas eros ac, tincidunt massa. Nulla feugiat odio metus, a blandit sapien ornare eu. Nunc convallis augue vitae sodales consequat. Maecenas libero mi, tempor non ante vitae, lobortis lobortis augue. Suspendisse potenti. Nulla facilisi.
</div>

<div id='footnotes'>
<sup id='fn1'>1. This is a bad wget joke, there's no such thing as wdata as far as I'm aware.<a href='#ref1' title='Get back to reading'>â†©</a></sup>
</div>